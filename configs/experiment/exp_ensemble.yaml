# @package _global_

defaults:
  - override /model: rs_ensemble_model.yaml
  - override /model/loss: mixed_loss.yaml
  - override /datamodule/transforms_train: transforms_1_400x400.yaml
  - override /datamodule/transforms_test: transforms_1_608x608.yaml
  # Color logging
  - override /hydra/hydra_logging: colorlog
  - override /hydra/job_logging: colorlog

seed: 12345
test: True
test_on_best: True

trainer:
  gpus: 1
  max_epochs: 500

model:
  architectures: ['/cluster/home/mdevita/Computational-Intelligence-Lab-2021/logs/ckpts/2021-07-27/10-02-51/epoch=356-val_kaggle=0.959.ckpt','/cluster/home/mdevita/Computational-Intelligence-Lab-2021/logs/ckpts/2021-07-27/10-52-20/epoch=261-val_kaggle=0.951.ckpt']

datamodule:
  batch_size: 8
  train_val_split: [80, 20]

callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "train_kaggle"   # name of the logged metric which determines when model is improving
    save_top_k: 1           # save k best models (determined by above metric)
    save_last: True         # additionaly always save model from last epoch
    mode: "max"             # can be "max" or "min"
    verbose: False
    dirpath: ${ckpts_dir}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    filename: '{epoch:02d}-{val_kaggle:.3f}'

  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "train_kaggle"   # name of the logged metric which determines when model is improving
    patience: 150           # how many epochs of not improving until training stops
    mode: "max"             # can be "max" or "min"
    min_delta: 0            # minimum change in the monitored metric needed to qualify as an improvement

  lr_monitor:
    _target_: pytorch_lightning.callbacks.lr_monitor.LearningRateMonitor
    logging_interval: 'epoch'

